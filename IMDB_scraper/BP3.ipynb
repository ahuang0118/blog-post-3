{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is blog post is to create a python script that acts as a web scrapper. This tool aims to find the movie or TV shows that share actors with a given show. In this way, the tool can recommend movie or TV shows to the user once the user provides their favorite, based on information on IMDb. <br>\n",
    "<br>\n",
    "### ยง1 Scrapy\n",
    "To start a scrapy project, we need to run the following command in command prompt/terminal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate PIC16B\n",
    "scrapy startproject IMDB_scraper\n",
    "cd IMDB_scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the directory and files that we will need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start on wiritng the scraper script. Create `imdb_spider.py` in the `spiders` directory and set it up by entering the following code. I am going to use my favorite TV show, *Friends*, as an example, and the `start_urls` is its IMDb page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request\n",
    "import scrapy\n",
    "\n",
    "class ImdbSpider(scrapy.Spider):\n",
    "    name = 'imdb_spider'\n",
    "    \n",
    "    start_urls = ['https://www.imdb.com/title/tt0108778/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a spider named `imdb_spide`. Then, we need to write parse functions for the `ImdbSpider` class so that the scraper can go through all actors in this TV show and obtain the names of all TV shows and movies that they have worked in. <br>\n",
    "<br> Let's start with `parse(self,response)`. This function has one simple task, that is to take us to the \"Full Cast & Crew\" page, which has the url `<start_urls>fullcredits`. Once arrived at the full credits page, a second function, `parse_full_credits(self,response)`, is called in the `callback` argument of `scrapy.Request`. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to go to the full credits page\n",
    "def parse(self,response):\n",
    "        # Join current url with \"fullcredits\"\n",
    "        full_credits = response.urljoin(\"fullcredits\")\n",
    "        yield scrapy.Request(full_credits, callback = self.parse_full_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second function, `parse_full_credits(self,response)` needs to go the actor page of all actors who worked in *Friends*. To find the url to the actor pages, we can make use of the web developer tool:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the screen shot, the url to the actor page is the `\"href\"` attribute in a in the element `\"td.primary_photo a\"`. And with experimenting in scrapy shell (run `scrapy shell <start_urls>fullcredits` in terminal), it is clear that this information can be extracted using `response.css`. Once got to the actor page, the third function `parse_actor_page(self, response)` is called, again in the `callback` argument of `scrapy.Request`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to go to all actor pages\n",
    "def parse_full_credits(self,response):\n",
    "    # List comprehension to obtain all urls to actor pages\n",
    "    actor_pages = [a.attrib[\"href\"] for a in response.css(\"td.primary_photo a\")]\n",
    "    for page in actor_pages:\n",
    "        actcor_page = response.urljoin(page)\n",
    "        yield scrapy.Request(actcor_page, callback = self.parse_actor_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we need to write the function `parse_actor_page(self, response)`. This function yield dictionaries with the actor's name and all the movies and TV shows that the actor has been in. To find how we can obtain the two pieces of information, we need to use the web developer tool again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them are text information and can be obtained using `.get()` method. Again with experimenting in scrapy shell, it is found that the `actor_name` is in the class `\"h1.header span.itemprop\"` and the `movie_or_TV_name` is in `\"div.filmo-row b a\"` element. `set()` is used to avoid multiple entries, which could happen when the actors also acts as producer or other roles. This function is shwon below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to yield actor_name and movie_or_TV_name in dictionaries \n",
    "def parse_actor_page(self, response):\n",
    "        actor_name = response.css(\"h1.header\").css(\"span.itemprop::text\").get()\n",
    "        # use set to avoid multiple entries\n",
    "        movie_or_TV_list = set([a.get() for a in response.css(\"div.filmo-row b\").css(\"a::text\")])\n",
    "        for a in movie_or_TV_list:\n",
    "            movie_or_TV_name = a\n",
    "            yield {\"actor\" : actor_name, \"movie_or_TV_name\" : movie_or_TV_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the spider is ready! We can run it and save the results to `results.csv` by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy crawl imdb_spider -o results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ยง2 Making Recommendations\n",
    "Since we already obtained the table of all movies and TV shows that all actors/actresses in *Friends* have worked in, we can now find the ones that share the most actors/actresses with *Friends*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read `results.csv` as a pandas data frame, and convert the movie_or_TV_name column to a set. Then, we can just simply count the number of times the movie or TV name has appeared in the results data frame by using `.sum()` method, and record the numbers by list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import results.csv\n",
    "results = pd.read_csv(\"results.csv\", sep = ',')\n",
    "# convert to set to avoid multiple entries and back to list for iterable\n",
    "movies_list = list(set(results[\"movie_or_TV_name\"].tolist()))\n",
    "# record the number of shared actors by list comprehension\n",
    "num_of_shared_actors = [(results.movie_or_TV_name == movie).sum() for movie in movies_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make a new data frame with the lists `movies_list` and `num_of_shared_actors`, and sort the table by descending numbers of shared actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_or_TV_name</th>\n",
       "      <th>number_of_shared_actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Friends</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ER</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment Tonight</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSI: Crime Scene Investigation</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seinfeld</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Tonight Show with Jay Leno</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCIS</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jimmy Kimmel Live!</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NYPD Blue</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Late Night with Conan O'Brien</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Diagnosis Murder</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Celebrity Page</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Days of Our Lives</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The West Wing</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Good Morning America</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The View</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Rosie O'Donnell Show</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_or_TV_name  number_of_shared_actors\n",
       "0                          Friends                      854\n",
       "1                               ER                      188\n",
       "2            Entertainment Tonight                      145\n",
       "3   CSI: Crime Scene Investigation                      135\n",
       "4                            Today                      125\n",
       "5                         Seinfeld                      124\n",
       "6   The Tonight Show with Jay Leno                      116\n",
       "7                             NCIS                      113\n",
       "8               Jimmy Kimmel Live!                      110\n",
       "9                        NYPD Blue                      107\n",
       "10   Late Night with Conan O'Brien                       98\n",
       "11                  Criminal Minds                       97\n",
       "12                  Grey's Anatomy                       93\n",
       "13                Diagnosis Murder                       92\n",
       "14                  Celebrity Page                       92\n",
       "15               Days of Our Lives                       92\n",
       "16                   The West Wing                       87\n",
       "17            Good Morning America                       86\n",
       "18                        The View                       86\n",
       "19        The Rosie O'Donnell Show                       85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and sort data frame for recommendations\n",
    "recommendation = pd.DataFrame(data={\"movie_or_TV_name\":movies_list, \"number_of_shared_actors\":num_of_shared_actors})\n",
    "recommendation = recommendation.sort_values(by=\"number_of_shared_actors\", ascending=False )\n",
    "# Tidying up the Table\n",
    "recommendation = recommendation.reset_index()\n",
    "recommendation = recommendation.drop(\"index\", axis =1)\n",
    "# Show the top 20 reccomedations\n",
    "recommendation.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the number 1 is *Friends* itself! <br>\n",
    "<br>\n",
    "The codes and .csv files can be found in my GitHub repository: https://github.com/ahuang0118/blog-post-3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d23c531d93d35974a8c5b39e3fdd3cf34cec8d7d1c787311dd21b26955d6a28"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
